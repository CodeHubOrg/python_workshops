{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Bootcamp or Data Analyst Apprenticeship - see Slack Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas (\"panel data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas package is used to explore data, eg\n",
    " - Calculate statistical values (mean, max, min etc)\n",
    " - Clean data (dealing with outliers, missing data etc)\n",
    " - Manipulate data to get into an easier form to deal with\n",
    " - Plot data via Matplotlib\n",
    " - Feed data into machine learning packages, eg Scikit-learn\n",
    "\n",
    "#### Syntax is very similar to Numpy.  Pandas is already installed as part of Anaconda installation - otherwise would need to install it on your computer as a first step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are pandas - series and dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of a 'Series' and 'DataFrame' below; we won't worry too much about creating from scratch as, typically, you will use pandas for reading in data from a file or similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   # use pandas package and refer to it as 'pd' to save writing out\n",
    "\n",
    "# A series is effectively a column of data\n",
    "\n",
    "data_Series = [12, 8, 10, 11]\n",
    "\n",
    "attendance = pd.Series(data_Series)\n",
    "\n",
    "print(attendance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We could make the labelling a bit more helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some row labels\n",
    "\n",
    "attendance_labelled = pd.Series(data_Series, index = ['week_1', 'week_2', 'week_3', 'week_4'])\n",
    "\n",
    "attendance_labelled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### A DataFrame is multiple Series, stuck together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "\n",
    "data_df = {'Python' : [12, 8, 10, 11], 'Web101' : [6, 10, 8, 11], 'AI' : [11, 7, 6, 9]}\n",
    "\n",
    "profiles = pd.DataFrame(data_df, index = ['week_1', 'week_2', 'week_3', 'week_4'])\n",
    "\n",
    "profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's use a local database - if only to promote interesting datasets that are available.  This was chosen on the basis that it is quite small and illustrates some of the features you will tend to find - many more interesting ones are available:  https://opendata.bristol.gov.uk/pages/homepage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that all the import statements should go at the top of a programme\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_file = os.path.join(os.path.abspath(''), 'datafiles', 'public-toilets-community.csv')\n",
    "\n",
    "toilet_data = pd.read_csv(input_file)\n",
    "\n",
    "toilet_df = pd.DataFrame(toilet_data)\n",
    "\n",
    "toilet_df.head() # print 1st 5 rows by default.  Can use .head(n) to print 1st n rows, or tail(n) for last n rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can see that there is an 'OBJECTID' which (from reading the documentation) I know is a unique identifier for each location.  Hence, it makes sense to use that as our row index - but first we need to check whether there are any duplicates in the column; if so, then it won't work as an index.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = toilet_df['OBJECTID'].duplicated().any() # returns True if any duplicates, False otherwise\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Good - now we can read in the DataFrame again, but using the first column as an index column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toilet_data = pd.read_csv(input_file, index_col = [0]) # ie use first column as the index\n",
    "toilet_df = pd.DataFrame(toilet_data)\n",
    "toilet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### That's all there is to it - the data is now in a DataFrame and ready to be examined.  Similarly, can easily read in from JSON or SQL databases (for those who are familiar with them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Looking at the first few rows wasn't very helpful - too much information so not nicely laid out.  First command that is normally run on a new dataset is .info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toilet_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and manipulating the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's assume that we want to look at the spread of publicly available toilets by post-code so we can see which areas need further work to encourage businesses to join the scheme.  We will want to know when the are open and whether there are both female and accessible toilets by postcode.  The steps we will follow are:\n",
    " - Remove columns that are clearly not necessary\n",
    " - Look more closely at the data to see if there is any clearly wrong or missing - decide what to do about it\n",
    " - Have a look at data by postcode\n",
    " - Save as a file so that hard work isn't lost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the drop() function can be used to drop a column\n",
    "\n",
    "df_rd = toilet_df.drop(\"Ward\", axis = 1) # axis = 1 means we are dropping column; use axis = 0 to drop rows\n",
    "df_rd.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Good - \"ward\" is no longer appearing in our new dataframe.  However:\n",
    " - we'd really like to remove many columns at the same time, and\n",
    " - if we create a new dataframe every time we make a change then we will end up using lots of memory.  It would be better to change the existing dataframe - so long as recreating it isn't a problem in the event of mistakes!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll do both of these steps together\n",
    "# Put column headings in a list, and use inplace =True as an argument\n",
    "\n",
    "df_rd.drop([\"Changing Place\", \"Name\",\"Address\", \"Automatic opening door\", \"Pull cord monitored (Y/N/Times)\",\"Male (no. of)\",\n",
    "              \"Urinals (no. of)\",\"Radar Key\",\"Unisex (no.of)\",\"Accessibility info\",\n",
    "              \"Baby change\", \"Family Toilet\", \"Automatic Public Convenience\", \"Attended\", \"Full Time Staffing\", \n",
    "              \"geo_shape\", \"geo_point_2d\"], axis = 1, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the result\n",
    "df_rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I've been rather drastic - I might have wanted to look a bit more carefully at some of the columns before deleting them in real life, but it will do as an example.  \n",
    "#####  At this stage, I think I will save a copy so that if I stop work and pick it up again later, I don't have to re-run all the previous cells: it's not particularly an issue for this example, but it could be if you are looking at the Air Quality dataset which has several sensors sending hourly data for many years!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar code to reading in the file\n",
    "import os\n",
    "\n",
    "output_file = os.path.join(os.path.abspath(''), 'datafiles', 'dataset_acc.csv')\n",
    "df_rd.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### So now I'll re-import pandas library, so that if I want to pick up my work at a later stage, then I can start from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_filev1 = os.path.join(os.path.abspath(''), 'datafiles', 'dataset_acc.csv')\n",
    "\n",
    "acc_data = pd.read_csv(input_filev1, index_col = [0])\n",
    "\n",
    "acc_data                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's have a look at some of the functions that are available in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  top is the most frequent value in that column.  freq is the frequency with which the 'top' value appears (eg, 2 is that most frequent number of female toilets available and there are 19 locations with this number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### However, I am a little surprised that more characteristics aren't shown as a result of the describe() function - I'd normally expect to see the mean, 25% percentile, min and max for numeric columns.However, I can see from the .info() output that some of the columns are of type 'object' and this is a sign that they contain mixed types, eg, integer and strings.  Let's have a closer look - first at the female column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data.info() # as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data['Female (no. of)'].unique() # gives the number of unique values in the column (aka pandas Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Even better, we can see the frequency with which each of these occur, as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data['Female (no. of)'].value_counts() # gives the frequency of each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data.isna().sum() # gives the total instances of either blank, None or NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### So, putting these together I can deduce that for the Female Column:\n",
    "- there are 107 rows, of which 25 are either blank or NaN, and 87 have values\n",
    "- there is 1 value each for 'No' and 'Yes'\n",
    "- the values are actually being held as strings (presumably why the .describe() function didn't return a wealth of information!\n",
    "\n",
    "##### First we'll get rid of the NaN: we don't know why they are NaN as we don't know about the source of the data I'd probably want to either do more digging or, if that wasn't possible, leave them as NaN.  However, in the interests of showing some functionality of pandas, I'll replace them all with 99.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data['Female (no. of)'].fillna(99, inplace = True) # Fills all NaN & blanks with 99.\n",
    "\n",
    "acc_data # Let's have a look and see if the NaN has gone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OK - looks promising.  Let's just double check by looking at the number of NaNs and the frequency with which values appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data['Female (no. of)'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now let's address the 'Yes' and 'No' and the fact that the apparent integers are actually strings - all in one step.\n",
    "##### The .map(XYZ) function applies whatever is defined by XYZ to every value in a panda series.  Let's use this to convert all 'yes' and 'no's.  We won't do it inplace this time as it's quite a drastic change to make and it might go wrong and spoil the existing DataFrame, so let's create another column to capture te output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yes_no(x):\n",
    "    if x == 'Yes':\n",
    "        x = 1\n",
    "    elif x == 'No':\n",
    "        x = 0\n",
    "    elif type(x) == str:\n",
    "        x = int(x)\n",
    "    return x\n",
    "\n",
    "acc_data['Female'] = acc_data['Female (no. of)'].map(yes_no) # changes yes to 1 and no to 0.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc_data['Female'].value_counts() # now let's check by looking at the frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Looks good.  Now let's look at the DataFrame and the .describe() function to see if the results are any different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Better (don't forget that there are 25 values of 99, which is purely illustrative data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### So, now we can get rid of the Female (no. of) column, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data.drop('Female (no. of)', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we need to do the same for the information on Accessible toilets.  We already know that there are no blanks, so we just need to see how many  Yes and No's there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data['Accessible (no. of)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few small differences to the previous map() function, but very similar\n",
    "def yes(x):\n",
    "    if x.lower() == 'yes':\n",
    "        x = 1\n",
    "    elif type(x) == str:\n",
    "        x = int(x)\n",
    "    return x\n",
    "\n",
    "acc_data['Acc'] = acc_data['Accessible (no. of)'].map(yes) # changes yes to 1 and no to 0.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data['Acc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just give the DataFrame a once-over before deleting the redundant column\n",
    "acc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data.drop('Accessible (no. of)', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, let's look at 'groupby' - the ability to take combinations of rows or columns if it helps with analysis.  For example, a company might have a number of transactions for each customer, and they all need to be added together to look at the total sales distribution by customer\n",
    "##### In this case we want to see how the toilets are distributed around the city so grouping by Postcode seems sensible - though probably only based on the first 3 or 4 digits.  It will be easier to remove the last 3 digits of the postcode rather than select the first 3 or 4 digits.  Remember slicing of strings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_three(string):\n",
    "    return string[:-4] # note that I've removed 4 characters so that the whitespace is removed as well\n",
    "\n",
    "acc_data['postcode_v1'] = acc_data['Postcode'].map(last_three)\n",
    "acc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = acc_data.groupby(['postcode_v1']).sum()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### So the Female column doesn't look particularly sensible because we used 99 instead of blanks - you can improve on this in the exercises.  You would also want to carry out some sanity checking on the result to make sure that things like count, sum, mean etc are consistent with the original data, ie the code hasn't gone wrong somewhere!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
