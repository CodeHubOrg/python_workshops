{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Bootcamp or Data Analyst Apprenticeship - see Slack Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas (\"panel data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas package is used to explore data, eg\n",
    " - Calculate statistical values (mean, max, min etc)\n",
    " - Clean data (dealing with outliers, missing data etc)\n",
    " - Manipulate data to get into an easier form to deal with\n",
    " - Plot data via Matplotlib\n",
    " - Feed data into machine learning packages, eg Scikit-learn\n",
    "\n",
    "#### Syntax is very similar to Numpy.  Pandas is already installed as part of Anaconda installation - otherwise would need to install it on your computer as a first step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are pandas - series and dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of a 'Series' and 'DataFrame' below; we won't worry too much about creating from scratch as, typically, you will use pandas for reading in data from a file or similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   # use pandas package and refer to it as 'pd' to save writing out\n",
    "\n",
    "# A series is effectively a column of data\n",
    "\n",
    "data_Series = [12, 8, 10, 11]\n",
    "\n",
    "attendance = pd.Series(data_Series)\n",
    "\n",
    "print(attendance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We could make the labelling a bit more helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some row labels\n",
    "\n",
    "attendance_labelled = pd.Series(data_Series, index = ['week_1', 'week_2', 'week_3', 'week_4'])\n",
    "\n",
    "attendance_labelled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### A DataFrame is multiple Series, stuck together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "\n",
    "data_df = {'Python' : [12, 8, 10, 11], 'Web101' : [6, 10, 8, 11], 'AI' : [11, 7, 6, 9]}\n",
    "\n",
    "profiles = pd.DataFrame(data_df, index = ['week_1', 'week_2', 'week_3', 'week_4'])\n",
    "\n",
    "profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's use a local database - if only to promote interesting datasets that are available.  This was chosen on the basis that it is quite small and illustrates some of the features you will tend to find - many more interesting ones are available:  https://opendata.bristol.gov.uk/pages/homepage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that all the import statements should go at the top of a programme\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_file = os.path.join(os.path.abspath(''), 'datafiles', 'public-toilets-community.csv')\n",
    "\n",
    "toilet_data = pd.read_csv(input_file)\n",
    "\n",
    "toilet_df = pd.DataFrame(toilet_data)\n",
    "\n",
    "toilet_df.head() # print 1st 5 rows by default.  Can use .head(n) to print 1st n rows, or tail(n) for last n rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can see that there is an 'OBJECTID' which (from reading the documentation) I know is a unique identifier for each location.  Hence, it makes sense to use that as our row index - but first we need to check whether there are any duplicates in the column; if so, then it won't work as an index.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = toilet_df['OBJECTID'].duplicated().any() # returns True if any duplicates, False otherwise\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Good - now we can read in the DataFrame again, but using the first column as an index column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toilet_data = pd.read_csv(input_file, index_col = [0]) # ie use first column as the index\n",
    "toilet_df = pd.DataFrame(toilet_data)\n",
    "toilet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### That's all there is to it - the data is now in a DataFrame and ready to be examined.  Similarly, can easily read in from JSON or SQL databases (for those who are familiar with them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Looking at the first few rows wasn't very helpful - too much information so not nicely laid out.  First command that is normally run on a new dataset is .info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toilet_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and manipulating the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's assume that we want to look at the spread of publicly available toilets by post-code so we can see which areas need further work to encourage businesses to join the scheme.  We will want to know when the are open and whether there are accessible toilets by postcode.  The steps we will follow are:\n",
    " - Remove columns that are clearly not necessary\n",
    " - Look more closely at the data to see if there is any clearly wrong or missing - decide what to do about it\n",
    " - Have a look at data by postcode\n",
    " - Save as a file so that hard work isn't lost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the drop() function can be used to drop a column\n",
    "\n",
    "df_rdcd = toilet_df.drop(\"Ward\", axis = 1) # axis = 1 means we are dropping column; use axis = 0 to drop rows\n",
    "df_rdcd.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Good - \"ward\" is no longer appearing in our new dataframe.  However:\n",
    " - we'd really like to remove many columns at the same time, and\n",
    " - if we create a new dataframe every time we make a change then we will end up using lots of memory.  It would be better to change the existing dataframe - so long as recreating it isn't a problem in the event of mistakes!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll do both of these steps together\n",
    "# Put column headings in a list, and use inplace =True as an argument\n",
    "\n",
    "df_rdcd.drop([\"Changing Place\", \"Name\",\"Address\", \"Automatic opening door\", \"Pull cord monitored (Y/N/Times)\",\"Male (no. of)\",\n",
    "              \"Urinals (no. of)\",\"Radar Key\",\"Unisex (no.of)\",\"Accessibility info\",\n",
    "              \"Baby change\", \"Family Toilet\", \"Automatic Public Convenience\", \"Attended\", \"Full Time Staffing\", \n",
    "              \"geo_shape\", \"geo_point_2d\"], axis = 1, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rdcd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I've been rather drastic - I might have wanted to look a bit more carefully at some of the columns before deleting them in real life, but it will do as an example.  I might just save a copy so that if I stop work and pick it up again later, I don't have to re-run all the previous cells (not particularly an issue for this example, but could be if you are looking at the Air Quality dataset which has several sensors sending hourly data for many years!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar code to reading in the file\n",
    "import os\n",
    "\n",
    "output_file = os.path.join(os.path.abspath(''), 'datafiles', 'dataset_acc.csv')\n",
    "df_rdcd.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### So now I'll re-import pandas library, so that if I want to pick up my work at a later stage, then I can start from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_filev1 = os.path.join(os.path.abspath(''), 'datafiles', 'dataset_acc.csv')\n",
    "\n",
    "acc_data = pd.read_csv(input_filev1, index_col = [0])\n",
    "\n",
    "acc_data.head()                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's have a look at some of the functions that are available in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  top is the most frequent value in that column.  freq is the frequency with which the 'top' value appears (eg, 2 is that most frequent number of female toilets available and there are 19 locations with this number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### However, I am a little surprised that more characteristics aren't shown as a result of the describe() function - I'd normally expect to see the mean, 25% percentile, min and max for numeric columns.However, I can see from the .info() output that some of the columns are of type 'object' and this is a sign that they contain mixed types, eg, integer and strings.  Let's have a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data['Female (no. of)'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Even better, we can see the frequenct with which each of these occur, as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data['Female (no. of)'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### So, judgement is now required.  'No' can probably be best replaced by 0. 'Yes' means that there is at least one - if we had more time to look at the other columns we might be able to make an informed guess.  For now, maybe just be conservative and assume that 'Yes' can be replaced by 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The .map(XYZ) function applieswhatever is defined by XYZ to every value in a panda series.  Let's use this to convert all 'yes' and 'no's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yes_no(x):\n",
    "    if x == 'Yes':\n",
    "        x = 1\n",
    "    elif x == 'No':\n",
    "        x = 0\n",
    "    elif type(x) == str:\n",
    "        x = int(x)\n",
    "    return x\n",
    "\n",
    "acc_data['Female'] = acc_data['Female (no. of)'].map(yes_no) # changes yes to 1 and no to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc_data['Female'].value_counts() # now let's check by looking at the frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
